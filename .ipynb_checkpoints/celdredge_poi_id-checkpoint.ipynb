{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "r = 42\n",
    "\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "feature_list = ['poi',\n",
    "               'bonus',\n",
    "               'salary',\n",
    "               'deferral_payments',\n",
    "               'deferred_income',\n",
    "               'director_fees',\n",
    "               'exercised_stock_options',\n",
    "               'expenses',\n",
    "               'total_payments',\n",
    "               'total_stock_value',\n",
    "               'from_messages',\n",
    "               'from_poi_to_this_person',\n",
    "               'from_this_person_to_poi',\n",
    "               'loan_advances',\n",
    "               'long_term_incentive',\n",
    "               'other',\n",
    "               'restricted_stock',\n",
    "               'restricted_stock_deferred',\n",
    "               'salary',\n",
    "               'shared_receipt_with_poi',\n",
    "               'to_messages'\n",
    "               ]\n",
    "\n",
    "data = featureFormat(data_dict, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "\n",
    "import copy\n",
    "my_dataset = copy.deepcopy(data_dict)\n",
    "my_feature_list = copy.deepcopy(feature_list)\n",
    "\n",
    "for k in my_dataset.keys():\n",
    "    my_dataset[k]['ratio_to_poi_to_all_sent']  = 0\n",
    "    if (my_dataset[k]['from_poi_to_this_person'] != 'NaN') and (my_dataset[k]['from_messages'] != 'NaN') and (my_dataset[k]['from_messages'] != 0):\n",
    "        my_dataset[k]['ratio_to_poi_to_all_sent'] = float(my_dataset[k]['from_this_person_to_poi'])/float(my_dataset[k]['from_messages'])\n",
    "\n",
    "    my_dataset[k]['ratio_from_poi_to_all_received']  = 0\n",
    "    if (my_dataset[k]['from_this_person_to_poi'] != 'NaN') and (my_dataset[k]['to_messages'] != 'NaN') and (my_dataset[k]['to_messages'] != 0):\n",
    "        my_dataset[k]['ratio_from_poi_to_all_received'] = float(my_dataset[k]['from_poi_to_this_person'])/float(my_dataset[k]['to_messages'])\n",
    "\n",
    "\n",
    "for i in ['ratio_to_poi_to_all_sent','ratio_from_poi_to_all_received']:\n",
    "    if i not in my_feature_list:\n",
    "        my_feature_list.append(i)\n",
    "\n",
    "#source: https://discussions.udacity.com/t/nan-values-not-removed-by-featureformat/179405/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 168 candidates, totalling 168000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 224 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 1424 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=4)]: Done 3424 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 6224 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=4)]: Done 9824 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=4)]: Done 14224 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 19424 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 25424 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 32224 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 39824 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 48224 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 57424 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 67424 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 78224 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=4)]: Done 89824 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=4)]: Done 102224 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=4)]: Done 115424 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=4)]: Done 129424 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done 144224 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=4)]: Done 159824 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=4)]: Done 168000 out of 168000 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'my_classifier__n_neighbors': 1, 'select_features__k': 6} with a score of 0.30\n"
     ]
    }
   ],
   "source": [
    "## KNeighborsClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[1,2,3,4,5,6,7,9,11,13,15,17,19,21], \n",
    "              my_classifier__n_neighbors=[1,2,3,4,5,6,7,8,9,13,15,20])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=6, score_func=<function f_classif at 0x115f53de8>)), ('my_classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.80733\tPrecision: 0.30187\tRecall: 0.33900\tF1: 0.31936\tF2: 0.33086\n",
      "\tTotal predictions: 15000\tTrue positives:  678\tFalse positives: 1568\tFalse negatives: 1322\tTrue negatives: 11432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=6)),\n",
    "    ('my_classifier', KNeighborsClassifier(n_neighbors=1))\n",
    "    ]\n",
    "\n",
    "knn_classifier = Pipeline(knn_pipeline_steps)\n",
    "\n",
    "test_classifier(knn_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "https://discussions.udacity.com/t/different-accuracy-score-in-gridsearchcv/240608/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 7 candidates, totalling 7000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 212 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 1832 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done 4832 tasks      | elapsed:   21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'select_features__k': 'all'} with a score of 0.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 7000 out of 7000 | elapsed:   30.7s finished\n"
     ]
    }
   ],
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = GaussianNB()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21,'all'])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.4f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k='all', score_func=<function f_classif at 0x116624aa0>)), ('my_classifier', GaussianNB())])\n",
      "\tAccuracy: 0.36180\tPrecision: 0.15169\tRecall: 0.82450\tF1: 0.25623\tF2: 0.43691\n",
      "\tTotal predictions: 15000\tTrue positives: 1649\tFalse positives: 9222\tFalse negatives:  351\tTrue negatives: 3778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "gnb_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k='all')),\n",
    "    ('my_classifier', GaussianNB())\n",
    "    ]\n",
    "\n",
    "gnb_classifier = Pipeline(gnb_pipeline_steps)\n",
    "\n",
    "test_classifier(gnb_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 7 candidates, totalling 7000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 212 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 1112 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=4)]: Done 2612 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done 4712 tasks      | elapsed:   36.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'select_features__k': 3} with a score of 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 7000 out of 7000 | elapsed:   52.9s finished\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21,'all'])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.4f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=3, score_func=<function f_classif at 0x116624aa0>)), ('my_classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.84840\tPrecision: 0.40756\tRecall: 0.30200\tF1: 0.34693\tF2: 0.31850\n",
      "\tTotal predictions: 15000\tTrue positives:  604\tFalse positives:  878\tFalse negatives: 1396\tTrue negatives: 12122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "gnb_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=3)),\n",
    "    ('my_classifier', DecisionTreeClassifier())\n",
    "    ]\n",
    "\n",
    "gnb_classifier = Pipeline(gnb_pipeline_steps)\n",
    "\n",
    "test_classifier(gnb_classifier, my_dataset, my_feature_list)\n",
    "\n",
    "## why is F1 0.35 here but 0.31 above ??  ## are there other parameters to vary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 168 candidates, totalling 168000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 704 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done 2600 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=4)]: Done 5400 tasks      | elapsed:   38.7s\n"
     ]
    }
   ],
   "source": [
    "## KMeans\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = KMeans()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "# maybe add a parameter for n_init ?\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21], \n",
    "              my_classifier__n_clusters=[3,5,9],\n",
    "              my_classifier__n_init=[10,30,50])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=5, score_func=<function f_classif at 0x112c632a8>)), ('my_classifier', KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=0))])\n",
      "\tAccuracy: 0.56953\tPrecision: 0.15487\tRecall: 0.50000\tF1: 0.23649\tF2: 0.34585\n",
      "\tTotal predictions: 15000\tTrue positives: 1000\tFalse positives: 5457\tFalse negatives: 1000\tTrue negatives: 7543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##The best parameters are {'select_features__k': 2, 'my_classifier__n_clusters': 4} with a score of 0.51\n",
    "\n",
    "##The best parameters are {'select_features__k': 2, 'my_classifier__n_clusters': 3} with a score of 0.51\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "km_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=5)),\n",
    "    ('my_classifier', KMeans(n_clusters=2))\n",
    "    ]\n",
    "\n",
    "km_classifier = Pipeline(km_pipeline_steps)\n",
    "\n",
    "test_classifier(km_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## KMeans\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = KMeans()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "# maybe add a parameter for n_init ?\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21], \n",
    "              my_classifier__n_clusters=[3,5,9],\n",
    "              my_classifier__n_init=[10,30,50])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=)),\n",
    "    ('my_classifier', KMeans(n_clusters=))\n",
    "    ]\n",
    "\n",
    "r_classifier = Pipeline(r_pipeline_steps)\n",
    "\n",
    "test_classifier(r_classifier, my_dataset, my_feature_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
