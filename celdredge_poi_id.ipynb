{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "r = 42\n",
    "\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "feature_list = ['poi',\n",
    "               'bonus',\n",
    "               'salary',\n",
    "               'deferral_payments',\n",
    "               'deferred_income',\n",
    "               'director_fees',\n",
    "               'exercised_stock_options',\n",
    "               'expenses',\n",
    "               'total_payments',\n",
    "               'total_stock_value',\n",
    "               'from_messages',\n",
    "               'from_poi_to_this_person',\n",
    "               'from_this_person_to_poi',\n",
    "               'loan_advances',\n",
    "               'long_term_incentive',\n",
    "               'other',\n",
    "               'restricted_stock',\n",
    "               'restricted_stock_deferred',\n",
    "               'salary',\n",
    "               'shared_receipt_with_poi',\n",
    "               'to_messages'\n",
    "               ]\n",
    "\n",
    "data = featureFormat(data_dict, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "\n",
    "import copy\n",
    "my_dataset = copy.deepcopy(data_dict)\n",
    "my_feature_list = copy.deepcopy(feature_list)\n",
    "\n",
    "for k in my_dataset.keys():\n",
    "    my_dataset[k]['ratio_to_poi_to_all_sent']  = 0\n",
    "    if (my_dataset[k]['from_poi_to_this_person'] != 'NaN') and (my_dataset[k]['from_messages'] != 'NaN') and (my_dataset[k]['from_messages'] != 0):\n",
    "        my_dataset[k]['ratio_to_poi_to_all_sent'] = float(my_dataset[k]['from_this_person_to_poi'])/float(my_dataset[k]['from_messages'])\n",
    "\n",
    "    my_dataset[k]['ratio_from_poi_to_all_received']  = 0\n",
    "    if (my_dataset[k]['from_this_person_to_poi'] != 'NaN') and (my_dataset[k]['to_messages'] != 'NaN') and (my_dataset[k]['to_messages'] != 0):\n",
    "        my_dataset[k]['ratio_from_poi_to_all_received'] = float(my_dataset[k]['from_poi_to_this_person'])/float(my_dataset[k]['to_messages'])\n",
    "\n",
    "\n",
    "for i in ['ratio_to_poi_to_all_sent','ratio_from_poi_to_all_received']:\n",
    "    if i not in my_feature_list:\n",
    "        my_feature_list.append(i)\n",
    "\n",
    "#source: https://discussions.udacity.com/t/nan-values-not-removed-by-featureformat/179405/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 7 candidates, totalling 7000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 1340 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done 3340 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done 7000 out of 7000 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'select_features__k': 'all'} with a score of 0.2584\n",
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k='all', score_func=<function f_classif at 0x115e429b0>)), ('my_classifier', GaussianNB())])\n",
      "\tAccuracy: 0.36180\tPrecision: 0.15169\tRecall: 0.82450\tF1: 0.25623\tF2: 0.43691\n",
      "\tTotal predictions: 15000\tTrue positives: 1649\tFalse positives: 9222\tFalse negatives:  351\tTrue negatives: 3778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = GaussianNB()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21,'all'])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.4f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "#source: https://discussions.udacity.com/t/different-accuracy-score-in-gridsearchcv/240608/6\n",
    "\n",
    "gnb_classifier = grid.best_estimator_\n",
    "\n",
    "# use test_classifier to evaluate\n",
    "test_classifier(gnb_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k='all', score_func=<function f_classif at 0x116624aa0>)), ('my_classifier', GaussianNB())])\n",
      "\tAccuracy: 0.36180\tPrecision: 0.15169\tRecall: 0.82450\tF1: 0.25623\tF2: 0.43691\n",
      "\tTotal predictions: 15000\tTrue positives: 1649\tFalse positives: 9222\tFalse negatives:  351\tTrue negatives: 3778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "gnb_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k='all')),\n",
    "    ('my_classifier', GaussianNB())\n",
    "    ]\n",
    "\n",
    "gnb_classifier = Pipeline(gnb_pipeline_steps)\n",
    "\n",
    "test_classifier(gnb_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 168 candidates, totalling 168000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 224 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 1424 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=4)]: Done 3424 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 6224 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=4)]: Done 9824 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=4)]: Done 14224 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 19424 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 25424 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 32224 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 39824 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 48224 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 57424 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 67424 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 78224 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=4)]: Done 89824 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=4)]: Done 102224 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=4)]: Done 115424 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=4)]: Done 129424 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done 144224 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=4)]: Done 159824 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=4)]: Done 168000 out of 168000 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'my_classifier__n_neighbors': 1, 'select_features__k': 6} with a score of 0.30\n"
     ]
    }
   ],
   "source": [
    "## KNeighborsClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[1,2,3,4,5,6,7,9,11,13,15,17,19,21], \n",
    "              my_classifier__n_neighbors=[1,2,3,4,5,6,7,8,9,13,15,20])\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=6, score_func=<function f_classif at 0x115f53de8>)), ('my_classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.80733\tPrecision: 0.30187\tRecall: 0.33900\tF1: 0.31936\tF2: 0.33086\n",
      "\tTotal predictions: 15000\tTrue positives:  678\tFalse positives: 1568\tFalse negatives: 1322\tTrue negatives: 11432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=6)),\n",
    "    ('my_classifier', KNeighborsClassifier(n_neighbors=1))\n",
    "    ]\n",
    "\n",
    "knn_classifier = Pipeline(knn_pipeline_steps)\n",
    "\n",
    "test_classifier(knn_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 210 candidates, totalling 210000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=4)]: Done 3344 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=4)]: Done 6144 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=4)]: Done 9744 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 14144 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 19344 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 25344 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 32144 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 39744 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 48144 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=4)]: Done 57344 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done 67344 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done 78144 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=4)]: Done 89744 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=4)]: Done 102144 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=4)]: Done 115344 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=4)]: Done 129344 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 144144 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=4)]: Done 159744 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=4)]: Done 176144 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=4)]: Done 193344 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=4)]: Done 210000 out of 210000 | elapsed: 24.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'my_classifier__min_samples_split': 10, 'select_features__k': 19, 'my_classifier__criterion': 'entropy', 'my_classifier__max_features': None} with a score of 0.3578\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=r)\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21,'all'],\n",
    "                  my_classifier__max_features=[None, 'auto', 'log2'],\n",
    "                  my_classifier__criterion=['gini', 'entropy'],\n",
    "                  my_classifier__min_samples_split=[2, 3, 4, 5, 10]\n",
    "                 )\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.4f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=19, score_func=<function f_classif at 0x119eeb0c8>)), ('my_classifier', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best'))])\n",
      "\tAccuracy: 0.85120\tPrecision: 0.42961\tRecall: 0.35400\tF1: 0.38816\tF2: 0.36692\n",
      "\tTotal predictions: 15000\tTrue positives:  708\tFalse positives:  940\tFalse negatives: 1292\tTrue negatives: 12060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = grid.best_estimator_\n",
    "\n",
    "test_classifier(dt_classifier, my_dataset, my_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=19, score_func=<function f_classif at 0x119eeb0c8>)), ('my_classifier', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best'))])\n",
      "\tAccuracy: 0.85120\tPrecision: 0.42961\tRecall: 0.35400\tF1: 0.38816\tF2: 0.36692\n",
      "\tTotal predictions: 15000\tTrue positives:  708\tFalse positives:  940\tFalse negatives: 1292\tTrue negatives: 12060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "dt_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=19)),\n",
    "    ('my_classifier', DecisionTreeClassifier(random_state=r,min_samples_split=10,criterion='entropy',max_features=None))\n",
    "    ]\n",
    "\n",
    "dt_classifier = Pipeline(dt_pipeline_steps)\n",
    "\n",
    "test_classifier(dt_classifier, my_dataset, my_feature_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1000 folds for each of 210 candidates, totalling 210000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=4)]: Done 1576 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=4)]: Done 2476 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 4876 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 6376 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 8076 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 9976 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 12076 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 14376 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 16876 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done 19576 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 22476 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=4)]: Done 25576 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=4)]: Done 28876 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=4)]: Done 32376 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done 36076 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done 39976 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=4)]: Done 44076 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=4)]: Done 48376 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=4)]: Done 52876 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=4)]: Done 57576 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=4)]: Done 62476 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=4)]: Done 67576 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=4)]: Done 72876 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=4)]: Done 78376 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=4)]: Done 84076 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=4)]: Done 89976 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=4)]: Done 96076 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=4)]: Done 102376 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=4)]: Done 108876 tasks      | elapsed: 46.2min\n",
      "[Parallel(n_jobs=4)]: Done 115576 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=4)]: Done 122476 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=4)]: Done 129576 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=4)]: Done 136876 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=4)]: Done 144376 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=4)]: Done 152076 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=4)]: Done 159976 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=4)]: Done 168076 tasks      | elapsed: 73.0min\n",
      "[Parallel(n_jobs=4)]: Done 176376 tasks      | elapsed: 77.0min\n",
      "[Parallel(n_jobs=4)]: Done 184876 tasks      | elapsed: 80.8min\n",
      "[Parallel(n_jobs=4)]: Done 193576 tasks      | elapsed: 84.5min\n",
      "[Parallel(n_jobs=4)]: Done 202476 tasks      | elapsed: 88.3min\n",
      "[Parallel(n_jobs=4)]: Done 210000 out of 210000 | elapsed: 91.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'my_classifier__min_samples_split': 10, 'select_features__k': 3, 'my_classifier__criterion': 'entropy', 'my_classifier__max_features': None} with a score of 0.2985\n"
     ]
    }
   ],
   "source": [
    "## RandomForestClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "my_data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
    "labels, feature_values = targetFeatureSplit(my_data)\n",
    "folds = 1000\n",
    "cv = StratifiedShuffleSplit(\n",
    "     labels, folds, random_state=r)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=r)\n",
    "steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif)),\n",
    "    ('my_classifier', clf)\n",
    "    ]\n",
    "\n",
    "parameters = dict(select_features__k=[3,5,9,15,19,21,'all'],\n",
    "                  my_classifier__max_features=[None, 'auto', 'log2'],\n",
    "                  my_classifier__criterion=['gini', 'entropy'],\n",
    "                  my_classifier__min_samples_split=[2, 3, 4, 5, 10]\n",
    "                 )\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=cv, verbose=1, scoring='f1', n_jobs=4)\n",
    "\n",
    "grid.fit(feature_values, labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.4f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "\n",
    "# The best parameters are {'my_classifier__min_samples_split': 10, \n",
    "#                          'select_features__k': 3, \n",
    "#                          'my_classifier__criterion': 'entropy', \n",
    "#                          'my_classifier__max_features': None} with a score of 0.2985\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('select_features', SelectKBest(k=3, score_func=<function f_classif at 0x10e6ee140>)), ('my_classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=None, max_...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.85233\tPrecision: 0.42316\tRecall: 0.29600\tF1: 0.34834\tF2: 0.31493\n",
      "\tTotal predictions: 15000\tTrue positives:  592\tFalse positives:  807\tFalse negatives: 1408\tTrue negatives: 12193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "rf_pipeline_steps = [\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('select_features',SelectKBest(f_classif,k=3)),\n",
    "    ('my_classifier', RandomForestClassifier(random_state=r,min_samples_split=10,criterion='entropy',max_features=None))\n",
    "    ]\n",
    "\n",
    "rf_classifier = Pipeline(rf_pipeline_steps)\n",
    "\n",
    "test_classifier(rf_classifier, my_dataset, my_feature_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
